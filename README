1. VIRTUALBOX practice
	1. Create a Fedora 36 VM using the hypervisor of your preference. I'll use VirtualBox in my examples.
	2. Log into the VM, if root, it is a best practice to create a user with sudo privileges, and disable root login:
		$ useradd <user>
		$ usermod -aG wheel <user>
		$ passwd <user>
		$ visudo (optional, be careful)
		$ su - <user>
	3. Update the system: 
		$ sudo dnf update
	4. Shutdown the system:
		$ sudo shutdown -h now
	5. Enable port forwarding for SSH access:
		1. Open VirtualBox and select your VM.
		2. Go to Settings -> Network -> Adapter 1 -> Advanced
		3. Verify:
			1. Attached to: NAT
			2. Adapter type: Intel PRO/1000 MT Desktop
			3. Cable connected: yes
		4. Go to Port Forwarding, and add a new record:
			1. Name: SSH
			2. Protocol: TCP
			3. Host IP: 127.0.0.1
			4. Host Port: 2222
			5. Guest IP: <leave blank>
			6. Guest Port: 22
		5. OK, OK.
	6. Turn on the VM
	7. Open the terminal of your preference and access your VM:
		$ ssh <user>@127.0.0.1 -p 2222
	
2. CVS practice
	1. Create a GitHub account: https://github.com/
	2. Go to Settings -> Developer settings -> Personal access tokens -> Generate new token
		1. Add a note and select the desired expiration
		2. Select full access for repo scope
		3. Generate token
	2. Inside your VM, install git and clone learning_purposes repo:
		$ sudo dnf install git
		$ git clone https://github.com/picta/learning_purposes.git
			* As it is a public repo, you can clone it without authentication.
	3. Setup identity using the same information as on your GitHub account:
		$  git config --global user.email "you@example.com"
		$  git config --global user.name "Your Name"
	4. Check your settings:
		$ git config --list
	5. Push a commit to the repo:
		$ cd learning_purposes
		$ touch name.lastname
		$ git add name.lastname
		$ git status
			*Check status
		$ git commit -m "Adding name.lastname"
		$ git status
			*Check status
		$ git push
			*Authenticate using user and access token generated previously

		* In case you want to undo last commit: $ git reset --soft HEAD~1
	6. Create your own repo and play with it

3. GCC practice
	1. Log into the practice VM
	2. Install GCC
		$ sudo dnf install gcc
	3. Go to gcc folder
		$ cd learning_purposes/gcc
	4. Compile helloworld 
		$  gcc helloworld.c -o helloworld
	5. Run the code
		$ ./helloworld
	* Congratulations, you have just compiled and run C code!
	6. Compile and run name.c

3.1 MAKE practice
	1. Log into the practice VM
	2. Install dependencies
		$ sudo dnf install wget g++
	3. Download NMAP source code
		$ wget nmap-7.92.tar.bz2
	4. Uncompress wget
		$ tar -xvf nmap-7.92.tar.bz2 && cd nmap-7.92
	5. Verify that nmap is not installed on the system
		$ nmap
	6. Configure system-dependent variables and create Makefiles
		$ ./configure
	7. Compile
		$ make
	8. Install into the system binaries
		$ sudo make install
	* Congratulations, you have just compiled and run C++ application!
	9. Test installation
		$ nmap -sV -p 1-22 127.0.0.1
		* -sV enables version detection
		* Port 22 should be open on SSH service

4. DOCKER practice
	1. Create a Docker hub account: https://hub.docker.com/
	2. Install dnf-core-utils in order to be able to manage DNF repositories
		$ sudo dnf -y install dnf-plugins-core
	3. Add Docker repo
		$ sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo
	4. Install docker engine and needed tools
		$ sudo dnf install docker-ce docker-ce-cli containerd.io docker-compose docker-compose-plugin
	5. Start docker daemon and enable start on boot
		$ sudo systemctl start docker
		$ sudo systemctl enable docker
	6. Verify it is running
		$ ps -aux|grep docker
	7. Run hello-world container
		$ docker run hello-world
	9. List images
		$ docker images

	* If getting permission denied while trying to connect to the Docker daemon socket at unix. 
	  That's because your used is not configured to run docker, to configure it:
		1. Add docker group(if doesn't exist) and add your user there:
			$ sudo groupadd docker && sudo usermod -aG docker <user>
		2. Log out and log in to the server
		3. Verify: 
			$ docker images
			
	10. Create a custom image:
		1. Log into https://hub.docker.com/
		2. Go to https://hub.docker.com/repositories
		3. Click on "Create Repository"
		4. Specify a name and description, set it to public, then click on "Create"
		5. Enter docker directory
			$ cd learning_purposes/docker
		6. Log into docker Hub:
			$ docker login
			* Enter your user and password and see the success message
		7. Run docker-whale to verify 
			$ docker run picta/docker-whale
		8. Build an image from Dockerfile
			$ docker build . -t <user>/<DockerHubRepo>:<tag>
			* Example: docker build . -t picta/learning:01
		9. See the new image:
			$ docker images
		10. Run the image
			$ docker run <user>/<DockerHubRepo>:<tag>
			* Example: docker run picta/learning:01 
		10. Push the image
			$ sudo docker push <DockerHubUser>/<DockerHubRepo>:<tag>
			* Example: docker push picta/learning:01
		11. Remove the local image:
			$ docker rmi <DockerHubUser>/<DockerHubRepo>:<tag>
			* Example: docker rmi picta/learning:01
		12. Pull the image from the Hub and run it:
			$ docker pull <DockerHubUser>/<DockerHubRepo>:<tag>
			* Example: docker pull picta/learning:01

		* In case you want to empty the whole workspace:
			1. docker system prune
			2. docker rmi $(docker images -a -q)
			* In case of errors, add force flag: docker rmi --force $(docker images -a -q)

5. CI/CD practice
	1. Jenkins runs on port 8080 by default.
	   Use the same instructions as we did on VirtualBox practice, opening 8080 port instead
	2. Add Jenkins repo and key
		$ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
		$ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
	3. Install dependencies
		$ sudo dnf install java-11-openjdk -y
	4. Install Jenkins
		$ sudo dnf install jenkins -y
	5. Reload systemctl
		$ sudo systemctl daemon-reload
	6. Enable Jenkins service on every boot
		$ sudo systemctl enable jenkins
	7. Start Jenkins service and verify
		$ sudo systemctl start jenkins
			* First run it took a little long
		$ sudo systemctl status jenkins
	8. As firewalld must be running, open 8080 port
		$ sudo firewall-cmd --add-port=8080/tcp
	9. Make the change persistent at boots:
		$ sudo firewall-cmd --runtime-to-permanent
	10. Copy the admin password from initialAdminPassword file
		$ sudo cat /var/lib/jenkins/secrets/initialAdminPassword
	11. Open Jenkins web app http://127.0.0.1:8080
			* Using the port you forwarded to, in my case, I forwarded to the same port
	12. Paste the initialAdminPassword and continue
	13. Install suggested plugins
		* Wait for the installations
	14. Create admin user
	15. Click on Save and finish && Start using Jenkins
	16. Go to Dashboard -> New Item
	17. Assign a name, select "Freestyle project", and click on OK
	18. Go to Source Code Management, select Git and specify:
		1. Repository URL: https://github.com/picta/learning_purposes
		2. Credentials -> Add Jenkins credentials provider and specify:
			1. Domain: Global
			2. Kind: Username with password
			3. Scope: Global
			4: Username and Password: Use your git user and token
		3. Click on Add, and select the credentials from the drop down menu
	19. Make sure master branch is selected as branch to build
			* "*/master" should be the default value
	20. Add a SHELL Build step with following value: ./zero.sh 
	21. Click on Save
	22. Click on Build Now
		* At this point, A new build job should automatically appear in the Build History
	23. Click on the job number
	24. Go to Console Output and watch the execution log
	25. Verify it succeeded

6. AWS CLI practice
	part I
	1. Install AWS CLI:
		$ curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
		$ unzip awscliv2.zip
		$ sudo ./aws/install
		$ aws --version
	2. Configure AWS credentials:
		$ aws configure
		* Configurations goes to ~/.aws/
	3. Generate an SSH key using the console or the CLI:
		$ ssh-keygen -t rsa
	4. Run an instance:
		$ aws ec2 run-instances --image-id ami-02f3416038bdb17fb --count 1 --instance-type t2.micro --key-name mykey
		$ aws ec2 describe-instances --filters "Name=instance-type,Values=t2.micro" --query "Reservations[].Instances[].InstanceId"
	5. Add port 22 inbound rule to access the machine. 
		$ ssh -i key.pem ubuntu@mymachine.com
	part II
	6. Create an EKS cluster from the web console
	7. Intall needed tools
		1. You'll need an IAM role for the cluster access: 
			https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html
		2. You can create a VPC using cloudformation, anyway eksctl creates one for us, so it's not really needed.
			https://docs.aws.amazon.com/eks/latest/userguide/creating-a-vpc.html
		3. Install kubectl
			$ https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html
		4. Install eksctl
			https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html
	8. Update kubectl configuration
		$ aws eks update-kubeconfig --region region-code --name my-cluster
		* Configuration goes to ~/.kube/
	9. Verify installation:
		$ kubectl get svc
		$ kubectl version
		$ kubectl config view
		$ kubectl get namespace
	10. Deploy an app:
		$ kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1
		$ kubectl get deployments
		$ kubectl get events --sort-by=.metadata.creationTimestamp
		* You'll notice that the deployment fail, that's because there are no worker nodes, as a practice, you may want to set it up.
	11. Create an EKS cluster with everything ready, using cloudformation
		$ cd learning_purposes/k8s
		$ eksctl create cluster -f cluster.yaml
		* Installation takes about 30 minutes
	10. Deploy an app, on the new cluster:
		1.
			$ kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1
			$ kubectl get deployments 
			$ kubectl get pods
			$ kubectl describe pods
			$ kubectl proxy
				* run in separate window
			$ export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{"\n"}}{{end}}') 
			$ echo Name of the Pod: $POD_NAME
			$ curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/
			$ kubectl expose deployment/kubernetes-bootcamp --type="NodePort" --port 8080
			$ kubectl get services
			$ kubectl describe services/kubernetes-bootcamp
			$ export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}')
			$ kubectl exec -ti $POD_NAME -- curl localhost:8080

		2.
			$ cd learning_purposes/k8s
			$ kubectl apply -f load-balancer.yaml
			$ kubectl get deployments hello-world
			$ kubectl describe deployments hello-world
			$ kubectl get replicasets
			$ kubectl describe replicasets
			$ kubectl expose deployment hello-world --type=LoadBalancer --name=my-service
			$ kubectl get services my-service
			$ kubectl describe services my-service
			$ curl http://<external-ip>:<port>
	11. Remove cluster
		$ eksctl delete cluster -f cluster.yaml 
	12. Navigate and get familiar with the AWS console and CLI, try out commands.

7. IaC practice
	1. Create a Free tier account on https://aws.amazon.com/
	2. Go to the AWS console: https://aws.amazon.com/console/
	3. Create an Access Key:
		1. Click under your name on the top right of the screen and go to:
			Security Credentials -> Access Keys -> Create New Access Key -> Show Access Key
			* You'll use this information later to log from the CLI
	4. Install terraform
		$ sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/fedora/hashicorp.repo
		$ sudo dnf install terraform -y
		$ terraform --version
	5. Create S3 bucket:
		$ aws s3api create-bucket --bucket daniel-rodriguez-bucket --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2
		$ aws s3 ls
	7. Go to learning_purposes/learn_terraform
		$ cd learning_purposes/learn_terraform
	8. Modify backend.tf and main.tf according to your needs
		* Don't forget to add your SSH public key
	9. Initialize workspace
		$ terraform init
	10. Validate configuration
		$ terrafom validate
	11. Apply changes
		$ terraform apply
	12. Inspect state
		$ terraform show
		$ terraform state list
	13. SSH to ec2_instance:
		$ ssh -i ~/.ssh/id_rsa ubuntu@<Public IP>
	14. Destroy the env:
		$ terraform destroy	
